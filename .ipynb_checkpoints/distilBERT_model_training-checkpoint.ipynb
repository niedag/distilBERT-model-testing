{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b415fad-1ebc-4019-b745-c1bb8df5029a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Activate GPU for faster training by clicking on 'Runtime' > 'Change runtime type' and then selecting GPU as the Hardware accelerator\n",
    "# Then check if GPU is available\n",
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c8b4947-3736-4929-8c0c-87a0c7c4886f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: datasets in /home/niedag/.local/lib/python3.10/site-packages (2.18.0)\n",
      "Requirement already satisfied: transformers in /home/niedag/.local/lib/python3.10/site-packages (4.39.3)\n",
      "Requirement already satisfied: huggingface_hub in /home/niedag/.local/lib/python3.10/site-packages (0.22.2)\n",
      "Requirement already satisfied: fsspec[http]<=2024.2.0,>=2023.1.0 in /home/niedag/.local/lib/python3.10/site-packages (from datasets) (2024.2.0)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /home/niedag/.local/lib/python3.10/site-packages (from datasets) (15.0.2)\n",
      "Requirement already satisfied: multiprocess in /home/niedag/.local/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/niedag/.local/lib/python3.10/site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /home/niedag/.local/lib/python3.10/site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: filelock in /home/niedag/.local/lib/python3.10/site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/niedag/.local/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from datasets) (5.4.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/niedag/.local/lib/python3.10/site-packages (from datasets) (1.24.4)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /home/niedag/.local/lib/python3.10/site-packages (from datasets) (4.66.2)\n",
      "Requirement already satisfied: xxhash in /home/niedag/.local/lib/python3.10/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: pandas in /home/niedag/.local/lib/python3.10/site-packages (from datasets) (1.5.3)\n",
      "Requirement already satisfied: packaging in /home/niedag/.local/lib/python3.10/site-packages (from datasets) (23.2)\n",
      "Requirement already satisfied: aiohttp in /home/niedag/.local/lib/python3.10/site-packages (from datasets) (3.9.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/niedag/.local/lib/python3.10/site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/niedag/.local/lib/python3.10/site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /home/niedag/.local/lib/python3.10/site-packages (from transformers) (0.15.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/niedag/.local/lib/python3.10/site-packages (from huggingface_hub) (4.9.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/niedag/.local/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/niedag/.local/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/niedag/.local/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/niedag/.local/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/niedag/.local/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/niedag/.local/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.19.0->datasets) (2020.6.20)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/niedag/.local/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests>=2.19.0->datasets) (1.26.5)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.19.0->datasets) (3.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/niedag/.local/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas->datasets) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
      "E: Could not open lock file /var/lib/dpkg/lock-frontend - open (13: Permission denied)\n",
      "E: Unable to acquire the dpkg frontend lock (/var/lib/dpkg/lock-frontend), are you root?\n"
     ]
    }
   ],
   "source": [
    "# Install required libraries\n",
    "!pip install datasets transformers huggingface_hub\n",
    "!apt-get install git-lfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fa3c948-39b2-45dd-b728-8359cf835e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "from datasets import load_dataset\n",
    "imdb = load_dataset(\"imdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d46fa47-0676-4f15-9775-bd031f403170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'There is no relation at all between Fortier and Profiler but the fact that both are police series about violent crimes. Profiler looks crispy, Fortier looks classic. Profiler plots are quite simple. Fortier\\'s plot are far more complicated... Fortier looks more like Prime Suspect, if we have to spot similarities... The main character is weak and weirdo, but have \"clairvoyance\". People like to compare, to judge, to evaluate. How about just enjoying? Funny thing too, people writing Fortier looks American but, on the other hand, arguing they prefer American series (!!!). Maybe it\\'s the language, or the spirit, but I think this series is more English than American. By the way, the actors are really good and funny. The acting is not superficial at all...', 'label': 1}\n",
      "{'text': \"<br /><br />When I unsuspectedly rented A Thousand Acres, I thought I was in for an entertaining King Lear story and of course Michelle Pfeiffer was in it, so what could go wrong?<br /><br />Very quickly, however, I realized that this story was about A Thousand Other Things besides just Acres. I started crying and couldn't stop until long after the movie ended. Thank you Jane, Laura and Jocelyn, for bringing us such a wonderfully subtle and compassionate movie! Thank you cast, for being involved and portraying the characters with such depth and gentleness!<br /><br />I recognized the Angry sister; the Runaway sister and the sister in Denial. I recognized the Abusive Husband and why he was there and then the Father, oh oh the Father... all superbly played. I also recognized myself and this movie was an eye-opener, a relief, a chance to face my OWN truth and finally doing something about it. I truly hope A Thousand Acres has had the same effect on some others out there.<br /><br />Since I didn't understand why the cover said the film was about sisters fighting over land -they weren't fighting each other at all- I watched it a second time. Then I was able to see that if one hadn't lived a similar story, one would easily miss the overwhelming undercurrent of dread and fear and the deep bond between the sisters that runs through it all. That is exactly the reason why people in general often overlook the truth about their neighbors for instance.<br /><br />But yet another reason why this movie is so perfect!<br /><br />I don't give a rat's ass (pardon my French) about to what extend the King Lear story is followed. All I know is that I can honestly say: this movie has changed my life.<br /><br />Keep up the good work guys, you CAN and DO make a difference.<br /><br />\", 'label': 1}\n"
     ]
    }
   ],
   "source": [
    "# Create a smaller training dataset for faster training times\n",
    "small_train_dataset = imdb[\"train\"].shuffle(seed=42).select([i for i in list(range(3000))])\n",
    "small_test_dataset = imdb[\"test\"].shuffle(seed=42).select([i for i in list(range(300))])\n",
    "print(small_train_dataset[0])\n",
    "print(small_test_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0fa4187f-e174-4abb-8556-3fefd743e73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set DistilBERT tokenizer\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4521636a-d7a8-4df6-86fa-ef075bc875ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 3000/3000 [00:00<00:00, 10135.14 examples/s]\n",
      "Map: 100%|██████████| 300/300 [00:00<00:00, 11001.26 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Prepare the text inputs for the model\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True)\n",
    "\n",
    "tokenized_train = small_train_dataset.map(preprocess_function, batched=True)\n",
    "tokenized_test = small_test_dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e521838c-a52b-4da5-b45a-d4a860424e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use data_collector to convert our samples to PyTorch tensors and concatenate them with the correct amount of padding\n",
    "from transformers import DataCollatorWithPadding\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3cfce58f-ae67-4a92-8d55-7fee742b800b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Define DistilBERT as our base model:\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2a691949-e02b-4ecd-b102-6c572782bb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the evaluation metrics \n",
    "import numpy as np\n",
    "from datasets import load_metric\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    load_accuracy = load_metric(\"accuracy\")\n",
    "    load_f1 = load_metric(\"f1\")\n",
    "    \n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    accuracy = load_accuracy.compute(predictions=predictions, references=labels)[\"accuracy\"]\n",
    "    f1 = load_f1.compute(predictions=predictions, references=labels)[\"f1\"]\n",
    "    return {\"accuracy\": accuracy, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8a8f9035-f2c5-4643-8307-8382db6b3517",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mnotebook_login\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_session\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrite_permission\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Displays a widget to login to the HF website and store the token.\n",
       "\n",
       "This is equivalent to [`login`] without passing a token when run in a notebook.\n",
       "[`notebook_login`] is useful if you want to force the use of the notebook widget\n",
       "instead of a prompt in the terminal.\n",
       "\n",
       "For more details, see [`login`].\n",
       "\n",
       "Args:\n",
       "    new_session (`bool`, defaults to `True`):\n",
       "        If `True`, will request a token even if one is already saved on the machine.\n",
       "    write_permission (`bool`, defaults to `False`):\n",
       "        If `True`, requires a token with write permission.\n",
       "\u001b[0;31mFile:\u001b[0m      ~/.local/lib/python3.10/site-packages/huggingface_hub/_login.py\n",
       "\u001b[0;31mType:\u001b[0m      function"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Log in to your Hugging Face account \n",
    "# Get your API token here https://huggingface.co/settings/token\n",
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login(token: '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')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1c5703-fa9a-4778-9cb4-506a91ed1a1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
